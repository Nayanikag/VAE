{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "VAE.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tPLjLBfW8V7G"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvZ94wXdLLDx",
        "outputId": "8fe0d47c-c947-4248-afc5-66366c03f5fc"
      },
      "source": [
        "!pip install utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: utils in /usr/local/lib/python3.6/dist-packages (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFJhCs1-7quw"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55B8gEwZIMUt"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "from IPython.core.display import Image, display\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bR-WYK5Kqq1"
      },
      "source": [
        "CUDA_LAUNCH_BLOCKING=1\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "training_batch_size = 128"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvI9-OSy8dIt"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb-Ji3kSMB3o"
      },
      "source": [
        "# Load Training Data\n",
        "dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "num_train = len(dataset)\n",
        "# Only train against 10000 images to reduce the training time\n",
        "indices = list(range(num_train))\n",
        "train_idx = indices[:10000]\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=training_batch_size, sampler=train_sampler)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KmS8ce7E7yz"
      },
      "source": [
        "#test loader\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
        "num_test = len(test_dataset)\n",
        "# Only test against 200 images to reduce the testing time\n",
        "indices = list(range(num_test))\n",
        "test_idx = indices[:200]\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, sampler=test_sampler)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmatjTBH73Si"
      },
      "source": [
        "# Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Wmh9cit5KC3"
      },
      "source": [
        "# Flatten 2D image tensor to 1D array before feeding to neural network\n",
        "def convert2DTensorto1DTensor(img):\n",
        "    x = img.view(img.size(0), -1)\n",
        "    if torch.cuda.is_available():\n",
        "      x = Variable(x.cuda())\n",
        "    return x\n",
        "\n",
        "# Regularization parameter\n",
        "alpha = -0.2\n",
        "\n",
        "# Loss function - Combination of reconstruction error(BCELoss) and the KL diverzence for the distribution of latent variable at \n",
        "# end of encoder\n",
        "def loss_fn(x_bar, x, mu, logvar):\n",
        "    recon_loss = F.binary_cross_entropy(x_bar, x, size_average=False)\n",
        "    KLD_loss = alpha * torch.sum(1 + logvar - mu**2 -  logvar.exp())\n",
        "    return (recon_loss + KLD_loss)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWoma9hc766f"
      },
      "source": [
        "# Network Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atUTb8R2N-OX"
      },
      "source": [
        "# Network implementation of VAE with 3 encoder layers & 3 decoder layers\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, image_size=784, latent_dim=40):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(image_size, 400),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(400, 200),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(200, latent_dim*2)\n",
        "        ) \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 200),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(200, 400),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(400, image_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    # Reparameterize for backpropagation and resample from the reparametrized distribution\n",
        "    def reparameterize(self, mean, log_variance):\n",
        "        std = log_variance.mul(0.5).exp_()\n",
        "        random = torch.randn(*mean.size())\n",
        "        if torch.cuda.is_available():\n",
        "          random = random.cuda()\n",
        "        z_sampled = Variable(random)\n",
        "        z_reparam = mean + std * z_sampled\n",
        "        return z_reparam\n",
        "    # Implemtation of forward\n",
        "    def forward(self, x):\n",
        "        latent = self.encoder(x)\n",
        "        mean, log_variance = torch.chunk(latent, 2, dim=1)\n",
        "        sample = self.reparameterize(mean, log_variance)\n",
        "        return self.decoder(sample), mean, log_variance"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHF4wDg5Ol6J"
      },
      "source": [
        "model= VAE().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mavyEfIC8P2W"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7EBZtvG4keT"
      },
      "source": [
        "# We train for 1000 epochs\n",
        "epochs = 1000\n",
        "loss_values = []\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    flag = True\n",
        "    for idx, (images, _) in enumerate(dataloader):\n",
        "        images = convert2DTensorto1DTensor(images)\n",
        "        images_bar, mu, logvar = model(images)\n",
        "        loss = loss_fn(images_bar, images, mu, logvar)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()/ (len(dataloader) * training_batch_size)\n",
        "        if flag == True:\n",
        "          plt.subplot(1, 2, 1)\n",
        "          plt.imshow(torch.reshape(images.cpu()[0], (28,28)), cmap='gray')\n",
        "          plt.subplot(1, 2, 2)\n",
        "          plt.imshow(torch.reshape(images_bar.cpu().detach()[0], (28,28)), cmap='gray')\n",
        "          plt.show()\n",
        "          flag = False   \n",
        "        #running_loss = running_loss/128\n",
        "    loss_values.append(running_loss)\n",
        "    print(\"Epoch {} Loss: {:.2f}\".format(epoch+1, running_loss))\n",
        "plt.plot(np.array(loss_values), 'r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPLjLBfW8V7G"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8vla9384s9y"
      },
      "source": [
        "# Run the model for test images and calculate loss\n",
        "total_test_loss = 0.0\n",
        "for idx, (images, _) in enumerate(test_dataloader):\n",
        "  images = convert2DTensorto1DTensor(images)\n",
        "  recon_images, mu, logvar = model(images)\n",
        "  loss = loss_fn(recon_images, images, mu, logvar)\n",
        "  total_test_loss += loss.item()\n",
        "  for i in range(0, len(images)):\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(np.reshape(images[i].cpu().detach().numpy(), (28, 28)), cmap='gray')\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(np.reshape(recon_images[i].cpu().detach().numpy(), (28, 28)), cmap='gray')\n",
        "    plt.title(\"Reconstructed image\")\n",
        "    plt.show()\n",
        "avg_test_loss = total_test_loss/ len(test_dataloader)\n",
        "print(avg_test_loss)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}